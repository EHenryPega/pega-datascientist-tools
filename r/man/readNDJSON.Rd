% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cdh_utils.R
\name{readNDJSON}
\alias{readNDJSON}
\title{Efficient read of newline-delimited JSON (NDJSON) (aka line-delimited JSON (LDJSON),
JSON lines (JSONL), multi-line JSON), a common format for big data streaming.}
\usage{
readNDJSON(jsonFiles, acceptJSONLines = NULL, dropColumns = c())
}
\arguments{
\item{jsonFiles}{Either a single file with the JSON data, a folder that
we read the}

\item{acceptJSONLines}{Optional filter function. If given, this is applied
to the lines with JSON data and only those lines for which the function
returns TRUE will be parsed. This is just for efficiency when reading
really big files so you can filter rows early. This would most typically
be used internally when called from \code{readDSExport} and related.}

\item{dropColumns}{Optional list if columns that will be dropped. Dropping
will happen after converting (batches of) data to \code{data.table}.}
}
\value{
A \code{data.table} with the contents
}
\description{
Efficient read of newline-delimited JSON (NDJSON) (aka line-delimited JSON (LDJSON),
JSON lines (JSONL), multi-line JSON), a common format for big data streaming.
}
\examples{
\dontrun{readNDJSON("datamart.json")}
}
