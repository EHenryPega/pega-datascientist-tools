---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

```{r, echo=F, warning=F, error=F, include=FALSE}
library(pdstools)

# include below when developing the library
# sapply(list.files("~/Documents/pega/pega-datascientist-tools/r/R", "*.R", full.names = T), source)

library(data.table)
library(lubridate)
library(ggplot2)
library(colorspace)
library(scales)
library(knitr)
library(kableExtra)

theme_set(theme_light())
```

# Datamart Monitoring Tables

See https://docs.pega.com/decision-management-reference-materials/database-tables-monitoring-models and https://techdocs.rpega.com/x/nYjM.

Recommended approach to export them is described in https://github.com/pegasystems/pega-datascientist-tools/wiki/How-to-export-and-use-the-ADM-Datamart

Internal doc on the tables: https://techdocs.rpega.com/x/cYD2Ag

The two ADM tables are

| Table | Dataset | Description |
| --- | --- | --- |
| PR_DATA_DM_ADMMART_MDL_FACT | pyModelSnapshots | Model snapshot data |
| PR_DATA_DM_ADMMART_PRED | pyADMPredictorSnapshots | Predictor binning |


Other datamart tables are:

| Table | Dataset | Description |
| --- | --- | --- |
| PR_DATA_DM_SNAPSHOTS | pyGetSnapshot | The monitoring information that is stored in the monitoring data mart contains data that is related to the same point in time; that collection of monitoring data is called a snapshot. This table contains one record per snapshot per model. |
| PR_DATA_DM_BINARY_DISTRIBUTION | pyGetBinaryDistribution | For binary outcome models, the count of the positives and negatives is stored in a granular set of bins which are used to calculate the AUC and the ROC curves. The score distribution and the observed responses overlay occur during training. |
| PR_DATA_DM_CONTINGENCYTABLE | pyGetContingencyData | For categorical outcome models, the confusion matrix of responses is the main statistic. Each cell in the confusion matrix is stored as a record in the database table. The confusion matrix is used to calculate the performance values, such as the F-statistic for the model or the accuracy for the classes. |
| PR_DATA_DM_HISTOGRAM | pyGetHistogram | For continuous outcome models, the difference between the predicted outcome and the actual outcome is used to measure the performance. The distribution of these residual values is stored in bins of equal interval size. The Information that is gathered in the bins is used to calculate the root-mean-square error (RMSE) and mean absolute error (MAE) performance statistics for the model. |
| PR_DATA_DM_DISTRIBUTION | pyGetDistribution | not documented |
| PR_DATA_DM_SUMMARY | pyGetSummaries | not documented |

Notifications are stored in

| Table | Dataset | Description |
| --- | --- | --- |
| DATA_DM_NOTIFICATION | pyNotificationStore | This table contains Prediction Studio notifications that inform about sudden drops in predictive performance, models with low performance, or other issues with models. |

# Model snapshots

```{r}
dmSnapshots <- readDSExport("Data-DM-Snapshot_pyGetSnapshot", "../../data")
dmSnapshots[, pySnapShotTime := pdstools::fromPRPCDateTime(pySnapShotTime)]
dmSnapshots[, pyValue := as.numeric(pyValue)]

dmSnapshots %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```


# Binary models

Binary distribution

```{r}
dmBinaryDistribution <- readDSExport("Data-DM-BinaryDistribution_pyGetBinaryDistribution", "../../data")
dmBinaryDistribution[, pySnapShotTime := pdstools::fromPRPCDateTime(pySnapShotTime)]

dmBinaryDistribution %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```

# Categorical models

Contingency tables. CDH Sample currently does not have those.

```{r}
# dmContingencyTable <- readDSExport("Data-DM-ContingencyTable_pyGetContingencyData", "../../data")
# 
# dmContingencyTable %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```

# Regression models

Models with continuous outcomes. CDH Sample currently does not have those.

```{r}
# dmHistogram <- readDSExport("Data-DM-Histogram_pyGetHistogram", "../../data")
# 
# dmHistogram %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```

# Summaries

Contains JSON in pyData. This is internal and ntermediate information (distribution summaries) for model inputs. More 
information about the summary table here - https://techdocs.rpega.com/x/cYD2Ag (internal only). The data in these tables is used to 
calculate the metrics shown to the user in Prediction Studio. Once the metric has been calculated, this data is cleared (daily).

```{r}
dmSummary <- readDSExport("Data-DM-Summary_pyGetSummaries", "../../data")
dmSummary[, pySnapShotTime := pdstools::fromPRPCDateTime(pySnapShotTime)]

dmSummary %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```

# Distribution

For internal use

```{r}
dmDistribution <- readDSExport("Data-DM-Distribution_pyGetDistribution", "../../data")

dmDistribution %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```

# Notifications


```{r}
dmNotifications <- readDSExport("Data-DM-Notification_pyNotificationStore", "../../data")

dmNotifications %>% head() %>% kable() %>% kable_paper(bootstrap_options = "striped")
```




