{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A metric for Action Discrimination\n",
    "\n",
    "The usual metric to assess predictor strength is AUC. AUC is a good measure to discriminate between who will and who will not accept an action. But in \n",
    "CDH, the customer is often given and it is more interesting to see which predictors differentiate more between the actions than others. With the help\n",
    "of the BinAggregator class we can assess this. For each predictor, we first normalize the binning of the models and then determine how much the \n",
    "binnings differ from eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from pdstools import ADMDatamart, BinAggregator, cdh_utils\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "datafolder = Path(\"~/Downloads/cross-customers-cache/\").expanduser()\n",
    "dm = ADMDatamart(model_filename=str(Path(datafolder, \"CDHSample_ModelSnapshots.parquet\")),\n",
    "                 predictor_filename=str(Path(datafolder, \"CDHSample_PredictorSnapshots.parquet\")),\n",
    "                 subset=False)\n",
    "myAggregator = BinAggregator(dm, query=(pl.col(\"Positives\") > 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get overview of the predictors including their standard metrics (AUC, and feature importance if available). We'll do a weighted average over the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportanceExpr = (\n",
    "    pl.col(\"FeatureImportance\").last()\n",
    "    if \"FeatureImportance\" in myAggregator.all_predictorbinning.columns\n",
    "    else pl.lit(0.0)\n",
    ")\n",
    "\n",
    "predictorOverview = (\n",
    "    myAggregator.all_predictorbinning.group_by(\n",
    "        [\"PredictorName\", \"PredictorCategory\", \"ModelID\"]\n",
    "    )\n",
    "    .agg(\n",
    "        # pl.col(\"ModelID\").unique().sort(),\n",
    "        isNumeric=(pl.col(\"Type\") == \"numeric\").all(),\n",
    "        PredictorPerformance=pl.col(\"PerformanceBin\").last(),\n",
    "        FeatureImportance=featureImportanceExpr,\n",
    "        Bins=pl.col(\"BinIndex\").max(),\n",
    "        ResponseCount=pl.col(\"ResponseCount\").max(),\n",
    "    )\n",
    "    .filter(\n",
    "        pl.col(\"Bins\") > 2\n",
    "    )  # I think this gets rid of the AGB models as well, which is what we want\n",
    "    .sort(\n",
    "        [\n",
    "            \"PredictorName\",\n",
    "            \"ModelID\",\n",
    "        ]\n",
    "    )\n",
    "    .group_by([\"PredictorName\", \"PredictorCategory\"])\n",
    "    .agg(\n",
    "        pl.col(\"ModelID\"),\n",
    "        pl.col(\"isNumeric\").all(),\n",
    "        pl.col(\"Bins\").mean(),\n",
    "        PredictorPerformance=cdh_utils.weighted_average_polars(\n",
    "            \"PredictorPerformance\", \"ResponseCount\"\n",
    "        ),\n",
    "        FeatureImportance=cdh_utils.weighted_average_polars(\n",
    "            \"FeatureImportance\", \"ResponseCount\"\n",
    "        ),\n",
    "    )\n",
    "    .sort(\n",
    "        [\n",
    "            \"PredictorName\",\n",
    "        ]\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"PredictorName\").cast(pl.String),\n",
    "        pl.col(\"PredictorCategory\").cast(pl.String),\n",
    "    )\n",
    ")\n",
    "\n",
    "predictorOverview.head(2).collect().to_pandas().style.hide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the standard BinAggregator function to roll up all predictors over all models with a standardized binning. We could go more fancy and do roll-ups with a log or other distributions per predictor. Important is these roll ups are based on the exact same binning as the normalized binning created in the next cells.\n",
    "\n",
    "This can be quite time consuming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictorOverview.collect()[\"PredictorName\"].to_list()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_binning = []\n",
    "for i in tqdm(range(len(preds))):\n",
    "    overall_binning = overall_binning + [\n",
    "        myAggregator.roll_up(preds[i], n=10, return_df=True).with_columns(\n",
    "            # TODO this should be in the BinAggregator class and not be needed here\n",
    "            pl.col(\"BinIndex\").cast(pl.UInt32),\n",
    "            pl.col(\"Models\").cast(pl.UInt32),\n",
    "        )\n",
    "    ]\n",
    "overall_binning = pl.concat(overall_binning, how=\"vertical_relaxed\")\n",
    "\n",
    "overall_binning.head(20).to_pandas().style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the binning for each of the predictors, for each of the models. The target binning should be the very same as used in the overall roll-up. \n",
    "\n",
    "The normalized binning is then joined with the overall binning for that predictor. The difference between the \"lift\" in a bin of the normalized binning and the lift in the same bin of the overall roll-up is the factor we're interested in. We take the difference, roll up per model ID and then average those over all models.\n",
    "\n",
    "For the final results we join with the standard metrics (AUC and feature importance if available) for reporting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modelids(pred):\n",
    "    return (\n",
    "        predictorOverview.filter(pl.col(\"PredictorName\") == pred)\n",
    "        .select(pl.col(\"ModelID\").explode())\n",
    "        .collect()[\"ModelID\"]\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "\n",
    "def is_numeric(pred):\n",
    "    return (\n",
    "        predictorOverview.filter(pl.col(\"PredictorName\") == pred)\n",
    "        .select(pl.col(\"isNumeric\"))\n",
    "        .collect()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "\n",
    "def create_normalized_binning(pred):\n",
    "    if is_numeric(pred):\n",
    "        target = myAggregator.create_empty_numbinning(pred, n=10)\n",
    "        return pl.concat(\n",
    "            [\n",
    "                myAggregator.accumulate_num_binnings(\n",
    "                    pred,\n",
    "                    [id],\n",
    "                    target.clone(),\n",
    "                    # TODO the cast should be in the library\n",
    "                ).with_columns(\n",
    "                    pl.col(\"BinIndex\").cast(pl.UInt32),\n",
    "                    ModelID=pl.lit(id),\n",
    "                )\n",
    "                for id in get_modelids(pred)\n",
    "            ],\n",
    "            how=\"vertical_relaxed\",\n",
    "        )\n",
    "    else:\n",
    "        symbols = myAggregator.create_symbol_list(\n",
    "            pred, n_symbols=10, musthave_symbols=[]\n",
    "        )\n",
    "        return pl.concat(\n",
    "            [\n",
    "                # TODO the cast should be in the library\n",
    "                myAggregator.accumulate_sym_binnings(pred, [id], symbols).with_columns(\n",
    "                    pl.col(\"BinIndex\").cast(pl.UInt32), ModelID=pl.lit(id)\n",
    "                )\n",
    "                for id in get_modelids(pred)\n",
    "            ],\n",
    "            how=\"vertical_relaxed\",\n",
    "        )\n",
    "\n",
    "\n",
    "normalized_binning = []\n",
    "for i in tqdm(range(len(preds))):\n",
    "    normalized_binning = normalized_binning + [create_normalized_binning(preds[i])]\n",
    "\n",
    "predictor_metrics = (\n",
    "    (\n",
    "        pl.concat(\n",
    "            normalized_binning,\n",
    "            how=\"vertical_relaxed\",\n",
    "        )\n",
    "        .join(\n",
    "            overall_binning.select([\"PredictorName\", \"BinIndex\", \"Lift\"]),\n",
    "            on=[\"PredictorName\", \"BinIndex\"],\n",
    "            how=\"left\",\n",
    "            suffix=\"_overall\",\n",
    "        )\n",
    "        .with_columns(\n",
    "            Distance=(\n",
    "                pl.col(\"Lift_overall\") - pl.col(\"Lift\")\n",
    "            ).abs()  # or, ratio, or, something else...\n",
    "        )\n",
    "    )\n",
    "    .group_by([\"PredictorName\", \"ModelID\"])\n",
    "    .agg(Distance=pl.col(\"Distance\").mean())\n",
    "    .group_by(\"PredictorName\")\n",
    "    .agg(ACDISC=pl.col(\"Distance\").mean())\n",
    "    .join(\n",
    "        predictorOverview.select(\n",
    "            [\n",
    "                \"PredictorName\",\n",
    "                \"PredictorCategory\",\n",
    "                \"PredictorPerformance\",\n",
    "                \"FeatureImportance\",\n",
    "            ]\n",
    "        ).collect(),\n",
    "        on=\"PredictorName\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .sort(\"PredictorName\")\n",
    ")\n",
    "\n",
    "predictor_metrics.to_pandas().style.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(\n",
    "    predictor_metrics,\n",
    "    x=\"PredictorPerformance\",\n",
    "    y=\"ACDISC\",\n",
    "    color=\"PredictorCategory\",\n",
    "    hover_name=\"PredictorName\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
