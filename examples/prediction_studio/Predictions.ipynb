{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Overview\n",
    "\n",
    "This is a small notebook to report and analyse Prediction Studio data on Predictions. The underlying data is from the Data-DM-Snapshot table that is used to populate the Prediction Studio screen with Prediction Performance, Lift, CTR etc.\n",
    "\n",
    "As data this notebook accept data exported from PDC - which has a slightly altered format - as well as data directly exported from the pyGetSnapshot dataset in Pega.\n",
    "\n",
    "For a description of the datamart tables see https://docs-previous.pega.com/decision-management/87/database-tables-monitoring-models.\n",
    "\n",
    "Disclaimer: this is not a canned, robust and customer-facing notebook (yet). It's mostly used internally to validate Prediction data. Column names and file formats may need some more review to make it more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data\n",
    "\n",
    "First, we're going to show the raw data. The raw data is in a \"long\" format with e.g. test and control groups in separate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     predictions_raw_data \u001b[38;5;241m=\u001b[39m read_ds_export(data_export)\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     21\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m Prediction(predictions_raw_data\u001b[38;5;241m.\u001b[39mlazy())\n\u001b[0;32m---> 23\u001b[0m \u001b[43mpredictions_raw_data\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_pandas()\u001b[38;5;241m.\u001b[39mstyle\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import polars as pl\n",
    "import json\n",
    "from pdstools import read_ds_export, Prediction\n",
    "\n",
    "# path to dataset export here \n",
    "# e.g. PR_DATA_DM_SNAPSHOTS.parquet\n",
    "data_export = \"<Your Export Here>\" \n",
    "\n",
    "prediction = None\n",
    "if data_export.endswith(\".parquet\"):\n",
    "    predictions_raw_data = pl.read_parquet(Path(data_export).expanduser())\n",
    "    prediction = Prediction(predictions_raw_data.lazy())\n",
    "elif data_export.endswith(\".json\"):\n",
    "    print(\"Import of PDC JSON data not supported\")\n",
    "    sys.exit()\n",
    "elif data_export.endswith(\".zip\"):\n",
    "    # Assuming a direct export from the dataset\n",
    "    predictions_raw_data = read_ds_export(data_export).collect()\n",
    "    prediction = Prediction(predictions_raw_data.lazy())\n",
    "\n",
    "predictions_raw_data.head().to_pandas().style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Data\n",
    "\n",
    "The actual prediction data is in a \"wide\" format with separate fields for Test and Control groups. Also, it is only the \"daily\" snapshots and the numbers and date are formatted to be normal Polars types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions.head().collect().to_pandas().style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary by Channel\n",
    "\n",
    "Standard functionality exists to summarize the predictions per channel. Note that we do not have the prediction to channel mapping in the data (this is an outstanding product issue), so apply the implicit naming conventions of NBAD. For a specific customer, custom mappings can be passed into the summarization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.summary_by_channel().collect().to_pandas().style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Trends\n",
    "\n",
    "Summarization by default is over all time. You can pass in an argument to summarize by day, week or any other period as supported by the (Polars time offset string language)[https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.dt.offset_by.html].\n",
    "\n",
    "This trend data can then easily be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot.performance_trend(\"1w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.plot.lift_trend(\"1w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction.plot.ctr_trend(\"1w\", facetting=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction.plot.responsecount_trend(\"1w\", facetting=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
